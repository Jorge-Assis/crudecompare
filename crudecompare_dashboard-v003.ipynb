{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Write a Data Science Blog Post\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "There are more than 150 different crude oil grades traded in the international market. The relative value of each crude oil depends on its quality and the crude oil assay is the standard document used by the industry where the quality parameters are described for each grade.\n",
    "\n",
    "Crude assays are usually published by oil companies that operate or are shareholders of oil fields where the corresponding crude are produced. They provide a combination of physical and chemical data that uniquely describe or characterize a crude oil and allow for the evaluation of quality parameters.\n",
    "\n",
    "With this project, crude oil grades traded in the international oil market can be compared to evaluate the relative differences in the main parameters that define its quality and value. This type of comparison is the first step usually taken by traders and refineries to decide which grade will fit better on their economic and operational objectives.\n",
    "\n",
    "For this project, crude oil data is gathered from the websites of selected oil companies. After being treated, the dataset is saved on a csv file. For the data modelling, the k-nearest algorithm is used for regression and assess the relative distance of a k number of crude oil grades compared with a grade used as reference. With this method, we will find the answers for the following questions from the dataset:\n",
    "\n",
    "1. Given a certain crude oil grade, what is its best substitute?\n",
    "\n",
    "2. What are the main differences between two crude oil benchmarks?\n",
    "\n",
    "3. What are the 15 more expensive crude oil grades?\n",
    "\n",
    "The comparison method will focus on three main crude oil parameters from the crude assays: API gravity, Sulphur content and Total Acidity Number. Our blog published at Medium, contains more contextual information about this topic.\n",
    "\n",
    "## Data Understanding\n",
    "    \n",
    "The two types of information included in a typical crude oil assay are **bulk properties** (also known aa Whole Crude Properties) and **fractional properties** (also known as Cut Properties or composition for a specific boiling point).\n",
    "\n",
    "The bulk quality properties of crude assays are commonly used by traders and refineries on the first step they take to classify crude oil grades. Among the bulk properties, the most prevalent are the API (American Petroleum Institute) gravity number, which is related with the density, and the Sulphur content of the crude oil which basically defines the crude relative purity. Another third parameter that is relevant for most of the refineries is the level of acidity, measured by the Total Acid Number (TAN).\n",
    "\n",
    "To access the data, several websites, where crude oil assays are published, were analysed to define the automation process that could be suitable to extract the desired information and at the same time clean and prepare the data.\n",
    "\n",
    "Functions 1 to 13 defined below will allow the scrapping of a selected website to download the data from several crude oil assays and save it in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeyenry/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# === Imports and initialization ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import randint\n",
    "import colorsys \n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import json\n",
    "from itertools import filterfalse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import awoc\n",
    "# Initialize the AWOC class.\n",
    "my_world = awoc.AWOC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 1 ==\n",
    "def download_file(url, linkpartial, company, download_dir):        \n",
    "    ''' This function dowloads files from a given website.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            url: url for the website to read.\n",
    "            linkpartial: name and extension of the file to be downloaded.\n",
    "            company: company name.\n",
    "            download_dir: local directory where the file will be saved.\n",
    "    '''\n",
    "    # Check if folder /data/assays/company exist\n",
    "    # create folder if not exist\n",
    "    if os.path.exists(download_dir) != True:\n",
    "        os.mkdir(download_dir)\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('headless')\n",
    "    options.add_experimental_option(\"prefs\", {\n",
    "        \"download.default_directory\": download_dir,\n",
    "        \"download.prompt_for_download\": False,\n",
    "        \"download.directory_upgrade\": True,\n",
    "        \"plugins.always_open_pdf_externally\": True\n",
    "    })\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    print('Downloading file to disk')\n",
    "    print('THIS IS THE URL: ', url)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    driver.close()\n",
    "    #filePath = download_dir + linkpartial\n",
    "    print('\\tDone')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 2 ==\n",
    "def read_website(url):\n",
    "    ''' This function read a webpage and returns its content.\n",
    "    \n",
    "        ARGUMENTS:\n",
    "            url: url for the website to read \n",
    "    '''\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "    \n",
    "    content = driver.page_source\n",
    "    webcontent = BeautifulSoup(content, 'html5lib')\n",
    "\n",
    "    time.sleep(5)\n",
    "    driver.close()\n",
    "\n",
    "    return webcontent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 3 ==\n",
    "def get_fileslist(url, filetype):\n",
    "    ''' This function reads a webpage and returns a list with the\n",
    "        the files contained on the page.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            url: website url to read\n",
    "            filetype: file extension to be retrieved\n",
    "    '''\n",
    "\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "    files_list = []\n",
    "    \n",
    "    content = driver.page_source\n",
    "    webcontent = BeautifulSoup(content, 'html5lib')\n",
    "    \n",
    "    elems = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "    for elem in elems:\n",
    "        #print(elem)\n",
    "        link = elem.get_attribute('href')\n",
    "        if link is not None:\n",
    "            if '/' in link and filetype in link:\n",
    "        #        link = link.split('/')\n",
    "        #        targetItem = link[len(link)-1]\n",
    "                files_list.append(link)\n",
    "\n",
    "    time.sleep(0.5)\n",
    "    driver.close()\n",
    "\n",
    "    return files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 4 ==\n",
    "def find_value_indice(value, qlist):\n",
    "    ''' This function check a given list and returns the\n",
    "        index for a given value.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            value: element to be found \n",
    "            qlist: list of elements\n",
    "    '''\n",
    "    charlist = value.split(' ')\n",
    "    idx = -1\n",
    "    check = False\n",
    "    for elem in qlist:\n",
    "        idx += 1\n",
    "        #====================\n",
    "        for item in charlist:\n",
    "            if item in elem:\n",
    "                check = True\n",
    "            else:\n",
    "                check = False\n",
    "                break # finish inner loop\n",
    "        #=====================\n",
    "        if check == True:\n",
    "            break # finish outer loop\n",
    "    return check, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 5 ==\n",
    "def check_tag(dfColumn, tag):\n",
    "    ''' This function check a dataframe contains a given tag value.\n",
    "        Returnd TRUE if the tag is found.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            dfColumn: df column \n",
    "            tag: element to be found\n",
    "    '''\n",
    "    charlist = tag.split(' ')\n",
    "    for item in charlist:\n",
    "        if dfColumn.str.contains(item):\n",
    "            # do nothing\n",
    "            check = True\n",
    "        else:\n",
    "            check = False\n",
    "            break\n",
    "    \n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 6 ==\n",
    "def splitTags(tag):\n",
    "    charlist = tag.split(' ')\n",
    "    splitted = []\n",
    "    for item in charlist:\n",
    "        splitted.append(item)\n",
    "        \n",
    "    return splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 7 ==\n",
    "def get_parameters(df, tags_list):\n",
    "    ''' This function extracts selected values from a data frame and \n",
    "        returns a dictionary with key/value pairs representing the values \n",
    "        extracted based on the tag list.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            df: dataframe\n",
    "            tags_list: list of tags\n",
    "    '''\n",
    "    result = {}\n",
    "    col_list = df.columns\n",
    "    \n",
    "    for col_name in col_list:\n",
    "        \n",
    "        try:\n",
    "            df[col_name] = df[col_name].str.strip()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        for tag in tags_list:\n",
    "            searchfor = splitTags(tag)\n",
    "            \n",
    "            df = df.astype(str)\n",
    "            converted = df[df[col_name].str.contains('|'.join(searchfor))]\n",
    "            row_lists = converted.values.tolist()\n",
    "            \n",
    "            cleanedList = []\n",
    "            if len(row_lists) > 0:\n",
    "                for nlist in row_lists:\n",
    "                     # cleanedList = row_list[0]\n",
    "                    try:\n",
    "                        # remove 'nan' from the list\n",
    "                        cleanedList.append([*filterfalse(lambda i: i == 'nan', nlist)])\n",
    "\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "            if len(cleanedList) > 0:\n",
    "                for rlist in cleanedList:\n",
    "                    check, val_index = find_value_indice(tag, rlist)\n",
    "                    if check:\n",
    "                        # get the value which is one position after the value label in the list\n",
    "                        result[tag] = rlist.pop(val_index + 1)\n",
    "                        break\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 8 ==\n",
    "def read_assay(url, mfile_path, tags_list):\n",
    "    ''' This function reads an assay file and returns a dictionary with\n",
    "        the retrieved parametes, based on a list of tags.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            url: file url\n",
    "            mfile_path: file path on the local disk \n",
    "            tags_list: list of tags\n",
    "    '''\n",
    "    \n",
    "    print('This is the path to read: ', mfile_path)\n",
    "    \n",
    "    df = pd.read_excel(mfile_path, header=None, index_col=None)\n",
    "    nrcolumns = len(df.columns)\n",
    "    name_columns = [str(x) for x in range(0, nrcolumns)]\n",
    "    df.columns = name_columns\n",
    "    dic_parameters = get_parameters(url, df, tags_list)\n",
    "        \n",
    "    return dic_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 9 ==\n",
    "def format_output_totalenergies(parameters, grade, url, filePath):\n",
    "    ''' This function adjust the data format based on the file structure \n",
    "        retrieved from Totalenergies website.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            parameters: list of parameters\n",
    "            grade: grade name\n",
    "            url: website url\n",
    "            filepath: file path on the local disk\n",
    "    '''\n",
    "    try:\n",
    "        country_data = my_world.get_country_data(parameters['Country'])\n",
    "        continent_name = country_data['Continent Name']\n",
    "    except NameError:\n",
    "        continent_name = ''\n",
    "\n",
    "    try:\n",
    "        grade['Crude'] = parameters['Crude']\n",
    "    except KeyError: # could not find the crude name in the file, will use file name\n",
    "        fname = filePath.split('/')\n",
    "        fname = fname[len(fname) - 1].split('.')\n",
    "        fname = fname[len(fname) - 2]\n",
    "        parameters['Crude'] = fname\n",
    "\n",
    "    try:\n",
    "        grade['Assay Date'] = parameters['Assay']\n",
    "    except KeyError: # could not find the crude name in the file, will use file name\n",
    "        parameters['Assay'] = ''\n",
    "\n",
    "    grade['Crude'] = parameters['Crude']\n",
    "    grade['Assay Date'] = parameters['Assay']\n",
    "    grade['API'] = parameters['° API']\n",
    "    grade['Sulphur'] = parameters['Sulphur wt']\n",
    "    grade['Tan (mgKOH/g)'] = parameters['Acidity mg KOH/g']\n",
    "    grade['Country'] = parameters['Country']\n",
    "    grade['Pour Point, °C'] = parameters['Pour Point']\n",
    "    grade['Source'] = url\n",
    "    grade['Region'] = continent_name\n",
    "\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 10 ==\n",
    "def format_output_bp(parameters, grade, url, filePath):\n",
    "    ''' This function adjust the data format based on the file structure \n",
    "        retrieved from BP website.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            parameters: list of parameters\n",
    "            grade: grade name\n",
    "            url: website url\n",
    "            filepath: file path on the local disk\n",
    "    '''\n",
    "    try:\n",
    "        country_data = my_world.get_country_data(parameters['Origin:'])\n",
    "        continent_name = country_data['Continent Name']\n",
    "    except NameError:\n",
    "        continent_name = ''\n",
    "\n",
    "    try:\n",
    "        grade['Assay Date'] = parameters['Sample Date:']\n",
    "    except KeyError: # could not find the crude name in the file, will use file name\n",
    "        parameters['Sample Date:'] = ''\n",
    "\n",
    "    grade['Crude'] = parameters['Name:']\n",
    "    grade['Assay Date'] = parameters['Sample Date:']\n",
    "    grade['API'] = parameters['Gravity API']\n",
    "    grade['Sulphur'] = parameters['Total Sulphur']\n",
    "    grade['Tan (mgKOH/g)'] = parameters['Acidity (mgKOH/g)']\n",
    "    grade['Country'] = parameters['Origin:']\n",
    "    grade['Pour Point, °C'] = parameters['Pour Point']\n",
    "    grade['Source'] = url\n",
    "    grade['Region'] = continent_name\n",
    "\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 11 ==\n",
    "def format_output_exxon(parameters, grade, url, filePath):\n",
    "    ''' This function adjust the data format based on the file structure \n",
    "        retrieved from Exxon website.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            parameters: list of parameters\n",
    "            grade: grade name\n",
    "            url: website url\n",
    "            filepath: file path on the local disk\n",
    "    '''\n",
    "    \n",
    "    fname = filePath.split('/')\n",
    "    fname = fname[len(fname) - 1].split('assay')\n",
    "    fname = fname[0].split('_')\n",
    "    crude_name = ''\n",
    "    for word in fname:\n",
    "        crude_name += word + ' '\n",
    "    parameters['Name:'] = crude_name.replace('Crude Oil ', '').strip().upper()\n",
    "    \n",
    "    grade['Crude'] = parameters['Name:']\n",
    "    grade['Assay Date'] = ''\n",
    "    grade['API'] = parameters['Gravity API']\n",
    "    try:\n",
    "        grade['Sulphur'] = parameters['Sulfur wt%']\n",
    "    except KeyError:\n",
    "        grade['Sulphur'] = ''\n",
    "        \n",
    "    try:\n",
    "        grade['Tan (mgKOH/g)'] = parameters['Neutralization number (TAN)']\n",
    "    except KeyError:\n",
    "        grade['Tan (mgKOH/g)'] =''\n",
    "        \n",
    "    grade['Country'] = ''\n",
    "    \n",
    "    try:\n",
    "        grade['Pour Point, °C'] = parameters['Pour point']\n",
    "    except KeyError:\n",
    "        grade['Pour Point, °C'] = ''\n",
    "        \n",
    "    grade['Source'] = url\n",
    "    grade['Region'] = ''\n",
    "    \n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 12 ==\n",
    "def format_output_equinor(parameters, grade, url, filePath):\n",
    "    ''' This function adjust the data format based on the file structure \n",
    "        retrieved from Equinor website.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            parameters: list of parameters\n",
    "            grade: grade name\n",
    "            url: website url\n",
    "            filepath: file path on the local disk\n",
    "    '''\n",
    "    try:\n",
    "        country_data = my_world.get_country_data(parameters['Origin:'])\n",
    "        continent_name = country_data['Continent Name']\n",
    "    except NameError:\n",
    "        continent_name = ''\n",
    "\n",
    "    grade['Crude'] = parameters['Traded Crude:']\n",
    "    grade['Assay Date'] = parameters['Assay Date:']\n",
    "    grade['API'] = parameters['API Gravity']\n",
    "    grade['Sulphur'] = parameters['Total Sulphur']\n",
    "    grade['Tan (mgKOH/g)'] = parameters['Total Acid Number']\n",
    "    grade['Country'] = parameters['Origin:']\n",
    "    grade['Pour Point, °C'] = parameters['Pour Point']\n",
    "    grade['Source'] = url\n",
    "    grade['Region'] = continent_name\n",
    "    \n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == Function 13 ==\n",
    "def main_get_grades(url, sourcelist, filetype, company, query, download_files=True):\n",
    "    ''' This is the main function that starts the process to retrieve the data.\n",
    "        \n",
    "        ARGUMENTS:\n",
    "            url: website url\n",
    "            sourcelist: list of source file names\n",
    "            filetype: type of file to read\n",
    "            company: company name\n",
    "            query: list of parameters to retrieve\n",
    "            parameters: list of parameters\n",
    "            download_files: TRUE if files will be downloade, FALSE if files were\n",
    "                            previously downloaded\n",
    "    '''\n",
    "    grades = []\n",
    "    flist = []\n",
    "    count = 1\n",
    "    download_dir = os.getcwd() + '/data/crude_assays/' + company + '/'\n",
    "    for link in sourcelist:\n",
    "        if link is not None:\n",
    "            if '/' in link and filetype in link:\n",
    "                link = link.split('/')\n",
    "                targetItem = link[len(link)-1]\n",
    "                flist.append(targetItem)\n",
    "                \n",
    "    totalCount = len(flist)\n",
    "    \n",
    "    if download_files == True:\n",
    "        # === download assay files ===\n",
    "        for (linkpart, source) in zip(flist, sourcelist):\n",
    "            #grade = {}\n",
    "            print(\"Processing file %2d of %2d ...\" % (count, totalCount))\n",
    "            #soup = read_website(url)\n",
    "            download_file(source, linkpart, company, download_dir)\n",
    "            count += 1\n",
    "\n",
    "    # === read assay files ===\n",
    "    fileslist = [f for f in listdir(download_dir) if isfile(join(download_dir, f))]\n",
    "    totalCount = len(fileslist)\n",
    "    count = 1\n",
    "    for (mfile, source) in zip(fileslist, sourcelist):\n",
    "        grade = {}\n",
    "        print(\"Reading assay file %2d of %2d ...\" % (count, totalCount))\n",
    "        filePath = join(download_dir, mfile)\n",
    "        parameters = read_assay(url, filePath, query)\n",
    "        \n",
    "        #print('THESE ARE PARAMETERS:', parameters)\n",
    "        \n",
    "        if company == 'totalenergies':\n",
    "            grade = format_output_totalenergies(parameters, grade, url, filePath)\n",
    "         \n",
    "        if company == 'bp':\n",
    "            grade = format_output_bp(parameters, grade, url, filePath)\n",
    "            \n",
    "        if company == 'exxon':\n",
    "            grade = format_output_exxon(parameters, grade, url, filePath)\n",
    "            \n",
    "        if company == 'equinor':\n",
    "            grade = format_output_equinor(parameters, grade, url, filePath)\n",
    "        \n",
    "        grades.append(grade)\n",
    "        count += 1\n",
    "        # print('THESE ARE GRADES:', grades)\n",
    "        \n",
    "    return grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable definitions for data collection\n",
    "\n",
    "On the blocks below are defined the variables for selected oil companies. The chosen approach to collect the data from the internet is designed to use just one company at a time. The preliminary result will be saved on csv file containing the name of the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == PREPARE DATA FOR COMPANY 1 ==\n",
    "company_name = 'totalenergies'\n",
    "url = \"https://ts.totalenergies.com/business-customers/crude-assays/\"\n",
    "file_type = '.xlsx'\n",
    "query_list = ['Crude',\n",
    "              '° API',\n",
    "              'Sulphur wt',\n",
    "              'Acidity mg KOH/g', \n",
    "              'Country', \n",
    "              'Pour Point',\n",
    "              'Assay']\n",
    "\n",
    "flist = get_fileslist(url, file_type)\n",
    "final_results = main_get_grades(url, flist, file_type, company_name, query_list, download_files=False)\n",
    "ndf = pd.DataFrame(final_results)\n",
    "wdir = os.getcwd() + '/data/crude_assays/assays_summary/'\n",
    "ndf.to_csv(wdir + 'summary_crude_assays_' + company_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == PREPARE DATA FOR COMPANY 2 ==\n",
    "company_name = 'bp'\n",
    "url = \"https://www.bp.com/en/global/bp-trading-and-shipping/documents-and-downloads/technical-downloads/crudes-assays.html\"\n",
    "file_type = '.xls'\n",
    "query_list = ['Name:',\n",
    "             'Sample Date:',\n",
    "             'Gravity API',\n",
    "             'Total Sulphur',\n",
    "             'Acidity (mgKOH/g)', \n",
    "             'Origin:', \n",
    "             'Pour Point']\n",
    "\n",
    "flist = get_fileslist(url, file_type)    \n",
    "final_results = main_get_grades(url, flist, file_type, company_name, query_list, download_files=False)\n",
    "ndf = pd.DataFrame(final_results)\n",
    "wdir = os.getcwd() + '/data/crude_assays/assays_summary/'\n",
    "ndf.to_csv(wdir + 'summary_crude_assays_' + company_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == PREPARE DATA FOR COMPANY 3 ==\n",
    "company_name = 'exxon'\n",
    "url = \"https://corporate.exxonmobil.com/Crude-oils/Crude-trading/Assays-available-for-download\"\n",
    "file_type = '.xlsx'\n",
    "query_list = ['Gravity API',\n",
    "             'Sulfur wt%',\n",
    "             'Neutralization number (TAN)', \n",
    "             'Pour point']\n",
    "\n",
    "flist = get_fileslist(url, file_type)\n",
    "final_results = main_get_grades(url, flist, file_type, company_name, query_list, download_files=False)\n",
    "ndf = pd.DataFrame(final_results)\n",
    "wdir = os.getcwd() + '/data/crude_assays/assays_summary/'\n",
    "ndf.to_csv(wdir + 'summary_crude_assays_' + company_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == PREPARE DATA FOR COMPANY 4 ==\n",
    "company_name = 'equinor'\n",
    "url = \"https://www.equinor.com/energy/crude-oil-assays\"\n",
    "file_type = '.xlsx'\n",
    "query_list = ['Traded Crude:',\n",
    "              'Origin:',\n",
    "              'Assay Date:',\n",
    "              'API Gravity',\n",
    "             'Total Sulphur',\n",
    "             'Total Acid Number', \n",
    "             'Pour Point']\n",
    "\n",
    "flist = get_fileslist(url, file_type)\n",
    "if company_name == 'equinor': # need to exclude the link for the Equinor's summary file\n",
    "    newList = [item for item in flist if \"quality-overview-equinor-crudes\" not in item]\n",
    "    flist = newList\n",
    "    \n",
    "final_results = main_get_grades(url, flist, file_type, company_name, query_list, download_files=False)\n",
    "ndf = pd.DataFrame(final_results)\n",
    "wdir = os.getcwd() + '/data/crude_assays/assays_summary/'\n",
    "ndf.to_csv(wdir + 'summary_crude_assays_' + company_name + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "After running the cells above, the cell below will join the summary data of existing companies in just one file that will be used as the master dataset for the modelling and evaluation stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == JOIN ALL COMPANY DATA IN ONE FILE ==\n",
    "wdir = os.getcwd() + '/data/crude_assays/assays_summary/'\n",
    "fileslist = [f for f in listdir(wdir) if isfile(join(wdir, f))]\n",
    "df_list = []\n",
    "for mfile in fileslist:\n",
    "    df_list.append(pd.read_csv(join(wdir,mfile)))\n",
    "\n",
    "result = pd.concat(df_list)\n",
    "\n",
    "result.to_csv(wdir + 'master_crude_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: The following stages require the master dataset file ready to be used, after completion of the steps defined and described above. With this notebook I am providing the *master_crude_data.csv* file that was created as per above procedure. I did some additions manually, for additional cleaning and using data found on other sources and publications. Nevertheless, the steps above demonstrate the different steps and ways performed for scrapping the data, directly from a webpage or from a file that can be downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling\n",
    "\n",
    "The function *getneighbor_grades* receive the necessary arguments and after being adjusted, the data and corresponding parameters will be applied to the NearestNeighbors data model. The NearestNeighbors model is imported from the Scikit-Learn data science library. That model is based on the Euclidian space calculations that are applied for data regression and classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getneighbor_grades (reference_grade, countries, quality_criteria, k=5):\n",
    "    ''' This function, prepares the data and headings, set the\n",
    "    model and perform the predictions\n",
    "    \n",
    "    Arguments\n",
    "        reference_grade: reference grade name;\n",
    "        countries: is a list with the selected countries to be used as reference for\n",
    "            the grades comparison.\n",
    "        quality_criteria: list with the selected crude quality criteria;\n",
    "        k: number of nearest grades to be returned, including the reference grade as 1st item\n",
    "\n",
    "    Return:\n",
    "        1. a list of lists with the data of the k nearest grades found\n",
    "        2. a list of the grades eligible for comparison\n",
    "    '''\n",
    "    # read the data file\n",
    "    crude_data_df = pd.read_csv(datapath)\n",
    "    \n",
    "    # Get the parameters that will be used for the comparison\n",
    "    limit =  len(quality_criteria)\n",
    "    listParameters = []\n",
    "    col_names = ['Crude']\n",
    "    for i in range(0, limit):\n",
    "        if quality_criteria[i] == 'SULPHUR':\n",
    "            listParameters.append('Sulphur (%)')\n",
    "            col_names.append('Sulphur (%)')\n",
    "\n",
    "        elif quality_criteria[i] == 'TAN':\n",
    "            listParameters.append('Tan (mgKOH/g)')\n",
    "            col_names.append('Tan (mgKOH/g)')            \n",
    "        \n",
    "        else:\n",
    "            listParameters.append(quality_criteria[i])\n",
    "            col_names.append(quality_criteria[i])\n",
    "\n",
    "    # include additional columns\n",
    "    col_names.append('Country')\n",
    "    col_names.append('Notes')\n",
    "    \n",
    "    df1 = crude_data_df[col_names]\n",
    "\n",
    "\n",
    "    if 'Tan (mgKOH/g)' in df1.columns:\n",
    "        #Remove the rows containing NaN in the TAN column\n",
    "        df2 = df1[df1['Tan (mgKOH/g)'].notna()]\n",
    "        df2.reindex()\n",
    "    else:\n",
    "        df2 = df1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    #Prepare the items for the reference grade\n",
    "    ref_grade = df2.loc[df2['Crude'] == reference_grade]\n",
    "    ref_param = ref_grade[listParameters].values.tolist()\n",
    "    \n",
    "    #Filter the sample grades using the selected reference countries\n",
    "    df2 = df2.loc[df2['Country'].isin(countries)]\n",
    "\n",
    "    #In case the country of the reference grade is not chosen for the selection\n",
    "    #criteria, all the data of the reference grade need to be added back into the\n",
    "    #filtered dataframe (otherwise it will note be shown in the results)!\n",
    "    if ref_grade['Country'].iloc[0] not in countries:\n",
    "        df2 = df2.append(ref_grade)\n",
    "\n",
    "    # Take the values of all the existing grades for training, excluding the label, \n",
    "    # which is a string\n",
    "    samples = df2[listParameters].values.tolist()\n",
    "\n",
    "    # Need to verify that the sample size is bigger than k\n",
    "    if len(samples) < k:\n",
    "        k = len(samples)\n",
    "\n",
    "    # Apply the K NearestNeighbors model\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    # Train the model\n",
    "    neigh.fit(samples)\n",
    "    # Find the nearest elements to the reference grade\n",
    "    distance, indices = neigh.kneighbors(ref_param)\n",
    "    nGrade_values = []\n",
    "\n",
    "    # add the grades on the results list\n",
    "    for i in indices[0]:\n",
    "        nGrade_values = df2.iloc[i].values.tolist()\n",
    "        results.append(nGrade_values)\n",
    " \n",
    "    #If the reference_grade is not the 1st in the list, then move its position\n",
    "    #This may be required when reindex is used above\n",
    "    if results[0][0] != reference_grade:\n",
    "        for i in range(len(results)):\n",
    "            if results[i][0] == reference_grade:\n",
    "                temp = results[i]\n",
    "                results.remove(temp)\n",
    "                results.insert(0, temp)\n",
    "\n",
    "    #Insert the ranking value for the 'Ranking' column\n",
    "    for i in range(len(results)):\n",
    "        results[i].insert(0, i)\n",
    "        \n",
    "    # update the table header\n",
    "    col_names.insert(0, 'Ranking')\n",
    "    \n",
    "    return results, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figures_data (results, headings):\n",
    "    \"\"\" Prepare the results to be used for the chart(s).\n",
    "    Args\n",
    "        results: A list with the result values\n",
    "        headings: A list with the result headings for the table\n",
    "    Returns\n",
    "        resList: A list of dictionaries with the corresponding values for each grade\n",
    "    \"\"\"\n",
    "    \n",
    "    resList = []\n",
    "\n",
    "    for grade in results:\n",
    "        temp_dic = { }        \n",
    "        for item in headings:\n",
    "            if 'Crude' in item:\n",
    "                temp_dic['Crude'] = grade[headings.index('Crude')]\n",
    "            if 'API' in item:\n",
    "                temp_dic['API'] = grade[headings.index('API')]\n",
    "            if 'Sulphur (%)' in item:\n",
    "                temp_dic['Sulphur (%)'] = grade[headings.index('Sulphur (%)')]\n",
    "            if 'TAN' in item:\n",
    "                temp_dic['TAN'] = grade[headings.index('TAN')]\n",
    "\n",
    "        resList.append(temp_dic)\n",
    "\n",
    "    return resList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figures_mpl(df, features, nrGrades):\n",
    "    \"\"\" Creates visualizations using Matplotlib \n",
    "\n",
    "    Args\n",
    "        df: A pandas dataframe with the data to plot;\n",
    "        features: List of features to extract;\n",
    "        nrGrades: Nr of points to display;\n",
    "\n",
    "    Returns\n",
    "        fig: list containing plotly visualizations\n",
    "    \"\"\"\n",
    "    mpl_colors = ['red', 'rosybrown', 'maroon', 'chocolate', 'tomato', 'navy', \n",
    "                  'blue', 'plum', 'magenta', 'violet', 'green', 'lime', \n",
    "                  'mediumaquamarine', 'aquamarine', 'cyan', 'orange', 'oldlace', \n",
    "                  'tan', 'khaki', 'lightyellow', 'indigo', 'yellow', 'black', 'gray', 'lightgrey']\n",
    "\n",
    "    nrFeatures = len(features)    \n",
    "    \n",
    "    if nrFeatures == 1:\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        x_names = df['Crude'].tolist()\n",
    "        N = len(x_names)\n",
    "        freq_x = 1\n",
    "        xs = np.arange(N)\n",
    "        ys = df[features[0]].tolist()\n",
    "        plt.bar(xs, ys, \n",
    "                width=1, \n",
    "                color=mpl_colors, \n",
    "                edgecolor=\"white\", \n",
    "                tick_label=x_names,\n",
    "                linewidth=0.7)\n",
    "        plt.xticks(np.arange(0, N, freq_x))\n",
    "        plt.xticks(rotation = 45)\n",
    "        plt.xlabel('Crude')\n",
    "        plt.ylabel(features[0])\n",
    "        \n",
    "    if nrFeatures == 2:\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        x_names = df['Crude'].tolist()\n",
    "        xs = df[features[1]].values.tolist()\n",
    "        ys = df[features[0]].values.tolist()\n",
    "                \n",
    "        for (x, y, color, crude) in zip(xs, ys, mpl_colors, x_names):\n",
    "            plt.scatter(x, y, c=color, s=50, edgecolor='k', label=crude)\n",
    "        \n",
    "        plt.xlabel(features[1])\n",
    "        plt.ylabel(features[0])\n",
    "        plt.grid(True)\n",
    "        l1 = plt.legend(bbox_to_anchor=(1.04, 1), borderaxespad=0)\n",
    "\n",
    "    if nrFeatures == 3:\n",
    "        fig = plt.figure(figsize=(10, 5))\n",
    "        x_names = df['Crude'].tolist()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        xs = df['Sulphur (%)'].values.tolist()\n",
    "        ys = df['Tan (mgKOH/g)'].values.tolist()\n",
    "        zs = df['API'].values.tolist()\n",
    "        \n",
    "        for (x, y, z, color, crude) in zip(xs, ys, zs, mpl_colors, x_names):\n",
    "            ax.scatter(x, y, z, c=color, linewidth=0.5, label=crude)\n",
    "        \n",
    "        ax.set_xlabel('Sulphur (%)')\n",
    "        ax.set_ylabel('Tan (mgKOH/g)')\n",
    "        ax.set_zlabel('API')\n",
    "        plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_figs_clusters_mpl(df):\n",
    "    mpl_colors = ['red', 'rosybrown', 'maroon', 'chocolate', 'tomato', 'navy', \n",
    "                  'blue', 'plum', 'magenta', 'violet', 'green', 'lime', \n",
    "                  'mediumaquamarine', 'aquamarine', 'cyan', 'orange', 'oldlace', \n",
    "                  'tan', 'khaki', 'lightyellow', 'indigo', 'yellow', 'black', 'gray', 'lightgrey']\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    x_names = df['Crude'].tolist()\n",
    "    xs = df['Sulphur (%)'].values.tolist()\n",
    "    ys = df['API'].values.tolist()\n",
    "\n",
    "    for (x, y) in zip(xs, ys):\n",
    "        plt.scatter(x, y)\n",
    "        \n",
    "    plt.axhline(y=10, lw=3, linestyle = 'dashed', color='black')\n",
    "    plt.axhline(y=22.3, lw=3, linestyle = 'dashed', color='green')\n",
    "    plt.axhline(y=32.1, lw=3, linestyle = 'dashed', color='red')\n",
    "    plt.axhline(y=42.1, lw=3, linestyle = 'dashed', color='yellow')\n",
    "    plt.axvspan(-0.01, 0.5, facecolor='red', alpha=0.2)\n",
    "    \n",
    "    plt.text(5, 15, 'HEAVY', horizontalalignment='right', fontsize=10)\n",
    "    plt.text(5, 25, 'MEDIUM', horizontalalignment='right', fontsize=10)\n",
    "    plt.text(5, 35, 'LIGHT', horizontalalignment='right', fontsize=10)\n",
    "    plt.text(5, 45, 'EXTRA-LIGHT', horizontalalignment='right', fontsize=10)\n",
    "\n",
    "    plt.title(\"All Grades in Dataset\")\n",
    "    plt.xlabel('Sulphur (%)')\n",
    "    plt.ylabel('API')\n",
    "    plt.grid(True)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For the evaluation, the model will be used to assess 3 questions:\n",
    "\n",
    "1. Given a certain crude oil grade, what is its best substitute?\n",
    "\n",
    "2. What are the main differences between two crude oil benchmarks?\n",
    "\n",
    "3. What are the 15 more expensive crude oil grades?\n",
    "\n",
    "The input parameters will be the reference grade, the list of source countries, the list of properties and the number of grades to be compared. \n",
    "\n",
    "The output will be a table showing the grades ranked by proximity to the reference grade and the result can be also shown on a chart. Depending on the number of properties selected for comparison, the chart can be of 3 Dimension, 2 Dimension or 1 Dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "workingpath = os.getcwd()\n",
    "datapath = workingpath + '/data/master_crude_20220826.csv'\n",
    "df_data = pd.read_csv(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = df_data['Country'].sort_values().drop_duplicates().dropna().values.tolist()\n",
    "all_grades = df_data['Crude'].sort_values().drop_duplicates().dropna().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Set up Input parameters ============\n",
    "\n",
    "# Initialise the dropdown for Reference grade\n",
    "dropdown_refgrade = widgets.Dropdown(\n",
    "    options=all_grades,\n",
    "    description='Ref. Grade:',\n",
    "    value='Brent Blend'\n",
    ")\n",
    "\n",
    "# Initialise the dropdown list for Countries\n",
    "list_countries = widgets.SelectMultiple(\n",
    "    options=countries,\n",
    "    description='Countries:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Initialise the dropdown list for Quality properties\n",
    "quality_properties = widgets.SelectMultiple(\n",
    "    options=['API', 'Sulphur (%)', 'Tan (mgKOH/g)'],\n",
    "    value=['API', 'Sulphur (%)'],\n",
    "    description='Properties:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Initialise slider to select number of grades\n",
    "kvalues = widgets.IntSlider(\n",
    "    min=1,\n",
    "    max=20,\n",
    "    step=1,\n",
    "    description='Nr. Grades:',\n",
    "    value=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Set up Output ============\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def output_results(reference_grade, countries, quality_criteria, kvalue):\n",
    "    output.clear_output()\n",
    "    results, header = getneighbor_grades(reference_grade, countries, quality_criteria, kvalue)\n",
    "    df_result = pd.DataFrame(results, columns=header)\n",
    "    with output:\n",
    "        display(df_result)\n",
    "\n",
    "def btn_eventhandler(obj):\n",
    "    output.clear_output()\n",
    "    results, header = getneighbor_grades(\n",
    "                dropdown_refgrade.value, \n",
    "                list_countries.value, \n",
    "                quality_properties.value, \n",
    "                kvalues.value)\n",
    "    df_result = pd.DataFrame(results, columns=header)\n",
    "    chart = get_figures_mpl(df_result, quality_properties.value, kvalues.value)\n",
    "    display(df_result.style.hide_index())\n",
    "    \n",
    "def btn_cluster_eventhandler(obj):\n",
    "    chart = get_figs_clusters_mpl(df_data)\n",
    "#===================================================\n",
    "btn_submit = widgets.Button(description='Submit')\n",
    "btn_submit.on_click(btn_eventhandler)\n",
    "#\n",
    "btn_cluster = widgets.Button(description='Show Clusters')\n",
    "btn_cluster.on_click(btn_cluster_eventhandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Given a certain crude oil grade, what is its best substitute?\n",
    "\n",
    "Very often the refineries need to find substitutes to one particular feedstock grade. This may be required for many different reasons. For example, due to economic optimization or due to possible unavailability of the reference grade in the market. To perform the substitution assessment, the first step is to select the reference grade, then the number of grades to be compared is defined and finally the selection is adjusted by fine tuning the number of possible source countries.\n",
    "\n",
    "For example, let’s assume we want to find the best possible substitute for the Nigerian grade Agbami, within the closest 15 grades from the dataset. Below we will look at 3 different type of results for this question 1 to illustrate the features available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3D Assessment)**\n",
    "\n",
    "After running the cell bellow the parameters widgets will be displayed. Set the parameters as follow:\n",
    "\n",
    "- Ref. Grade: Select 'Agbami' (another grade can be selected if desired to be assessed)\n",
    "- Countries: Select all countries (click on the first item on the list, scroll down, press the shift key and click on the last)\n",
    "- Properties: Select all properties (select first item, press shift key, select last item)\n",
    "- Nr. Grades: Chose 15\n",
    "\n",
    "Then click on 'Submit' button. Below the widgets the results will be displayed on a table and on a **3d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c5506a0924442f9e8ebf414c1f5883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=8, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41794ca4df674415ab3bb31c8543ae7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above we can say that the best substitute grade for Agbami is Asgard Blend, followed by Condensate Ichthys, both produced in Australia. Because the three available parameters were selected, the result is also automatically plotted on a 3D chart.\n",
    "\n",
    "From the 3D chart, it can be seen visually the relative position of the compared grades based on the parameters, API, Tan and Sulphur content. While on the ranking table Asgard Blend is ranked as the closest to Agbami, on the 3D chart Agbami is shown closer to Condensate Ichthys (hovering over the chart points the names of the grades will be shown). This is due to the Tan value influence. On the used dataset the Tan value for some grades is unknown and it was set to zero. This is due to the Tan value influence. On the used dataset the Tan value for some grades is unknown and it was set to zero. The 2D assessment below can provide another perspective of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2D Assessment)**\n",
    "\n",
    "After running the cell bellow the parameters widgets will be displayed. Set the parameters as follow:\n",
    "- Ref. Grade: Select 'Agbami' (another grade can be selected if desired to be assessed)\n",
    "- Countries: Select all countries (click on the first item on the list, scroll own, press the shift key and click on the last)\n",
    "- Properties: **Select 'API' and 'Sulphur (%')**\n",
    "- Nr. Grades: Chose 15\n",
    "\n",
    "Then click on 'Submit' button. Below the widgets the results will be displayed on a table and on a **2d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4981341c45e4ab588b1b48e38dc5f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=8, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c6629263ca438ebfb22828ce7058de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking table of the grades above is unchanged and on the 2D chart it is clearer to see the relative position of the reference grade (Agbami) and its closest substitute (Asgard Blend)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1D Assessment)**\n",
    "\n",
    "After running the cell bellow the parameters widgets will be displayed. Set the parameters as follow:\n",
    "- Ref. Grade: Select 'Agbami' (another grade can be selected if desired to be assessed)\n",
    "- Countries: Select all countries (click on the first item on the list, scroll down, press the shift key and click on the last)\n",
    "- Properties: Select 'Sulphur (%)'\n",
    "- Nr. Grades: Chose 15\n",
    "\n",
    "Then click on 'Submit' button. Below the widgets the results will be displayed on a table and on a **1d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442f801ecb8740aba2565ce9c36ea585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=8, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6465976a434fe8a732fc6f68fac94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, in terms of sulphur content, Attaka and Bach Ho are the closest grades to Agbami. These results are very different from the previous two queries. Although it can be used to show the crudecompare dashboard feature to handle one-dimension comparisons. In fact, for the purpose of grade substitution assessment, the 1D assessment is less relevant than the 3D and 2D assesments shown earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What are the main differences between two crude oil benchmarks?\n",
    "\n",
    "Currently the main benchmarks for crude oil are, WTI from USA, Dated Brent from Northern Western Europe and OPEC, a basket of crude oil from different countries that are members of the Organization of Petroleum Exporting Countries (OPEC). Other Official Selling Prices (OSPs) are used in several parts of the world as localized market reference, but their pricing mechanisms are also influenced by the main benchmarks mentioned above.\n",
    "\n",
    "For this assessment, Brent is selected as the reference grade and for countries only UK and US are selected, because they are the source countries. This will bring those two benchmarks within the range of 15 grades to compare.\n",
    "\n",
    "After running the cell bellow the parameters widgets will be displayed. Set the parameters as follow:\n",
    "- Ref. Grade: Select 'Brent Blend'\n",
    "- Countries: Select 'US', 'USA', 'United Kingdom' and 'United States' (click on the first item on the list, scroll down, press the ctrl key and select the other items)\n",
    "- Properties: Select 'API' and 'Sulphur (%')\n",
    "- Nr. Grades: Chose 15\n",
    "\n",
    "Then click on 'Submit' button. Below the widgets the results will be displayed on a table and on a **2d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee95941f0e234b6b9c9c5ee6ec7221af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=46, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b832eaa289d849ddb97bb7896ae182bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a direct comparison, WTI is lighter and sweeter than Brent. Just because of that, we could infer that WTI is more expensive than Brent. But, looking at the relative performance of those two benchmarks in the last five years, Brent has been valued above WTI most of the time.\n",
    "\n",
    "This is because while WTI is mainly used by US consumers, Brent is used to price about two thirds of the crude oil traded in the global market, including grades supplied by OPEC.\n",
    "\n",
    "Between Brent and WTI there are four other grades, namely, LLS, Niobrara, WTS and Dumbarton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: How to find the 15 most expensive crude oil grades\n",
    "\n",
    "After running the cell bellow the parameters widgets will be displayed.\n",
    "Then click on 'Show Clusters' button. Below the widgets the results will be displayed on a **2d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b79ceacd83499483f76f9f2cccf2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=46, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21839d6b42c8490390dcd5cb289dd23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the chart above are plotted all the grades contained in the analysed dataset. Crude oils with API degree below 10 are classified as Extra-Heavy, between 10 and 22 are classified as Heavy, Medium grades are considered between 22 and 32, between 32 and 42 are Light and all above 42 are Extra-Light grades.\n",
    "\n",
    "It is worth to note that the clear-cut definition of light and heavy crude is not uniform in all the industry. The classification is based more on practical aspects than theoretical.\n",
    "\n",
    "Crude oil grades with high sulphur content and low API are least expensive. Based on that, we can expect to find the most valuable crude oil grades within the top side of the range shown in pink on the chart above, representing the sweet crudes range, i.e, with low sulphur content.\n",
    "\n",
    "From a previous query (when looking for a substitute grade for Agbami), we know that Condensate Senipah is in the top range with an API of 50. So, we will use it as the reference grade to zoom in that top left corner of the dataset and look at the closest 15 grades. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the cell bellow the parameters widgets will be displayed. Set the parameters as follow:\n",
    "- Ref. Grade: Select 'Condensate Senipah'\n",
    "- Countries: Select all countries (click on the first item on the list, scroll down, press the shift key and click on the last)\n",
    "- Properties: Select 'API' and 'Sulphur (%')\n",
    "- Nr. Grades: Chose 15\n",
    "\n",
    "Then click on 'Submit' button. Below the widgets the results will be displayed on a table and on a **2d chart**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfd41f558414d9fa8915bae30af5b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Ref. Grade:', index=52, options=('AASGARD BLEND', 'AKPO BLEND', 'AL JURF'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d02ffd5f794006b1d7021ddc59e50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=15, description='Nr. Grades:', max=20, min=1), Button(description='Submit', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Interface Dashboard: Input & Output =============\n",
    "input_widgets_row1 = widgets.HBox(\n",
    "[dropdown_refgrade, list_countries, quality_properties])\n",
    "\n",
    "input_widgets_row2 = widgets.HBox(\n",
    "[kvalues, btn_submit, btn_cluster])\n",
    "\n",
    "display(input_widgets_row1)\n",
    "display(input_widgets_row2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the chart above are plotted the sweeter and lighter crude oil grades in the analysed dataset. At least in terms of quality, we can say those are the most expensive crude oil grades.\n",
    "\n",
    "However, another layer of the analysis is required to fine tune this assessment. To have a more accurate conclusion, it is required to look at the historic and actual prices those grades are traded and make the final comparison. Price details are normally private and even with some costly subscriptions that are necessary to use, public disclosure is very difficult to obtain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
